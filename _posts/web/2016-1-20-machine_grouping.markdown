---
layout: post
title:  "速度优化-后端机器分组"
date:   2016-1-20 17:55:00
categories:  ["web","tornado", "速度优化"]
---

上周对网站的后端架构做了一次优化，方法就是根据url, 给后端机器分组，
从而提高了后端机器的缓存命中率，减轻了响应时间的波峰。现在对工作内容整理下。
其中主要涉及对网站架构的分析和实施方法。

#### 背景

我们网站的整体访问速度，平常速度在50ms, 到了pv高峰期(21点到23点)会产生175ms的波峰，原因与网站架构有关。

![](/assets/pic/2016/02/site-struct.png)

如上图所示， 我们网站的数据源有两个，redis 和 api,  后端tornado机器，通过网络请求获得
数据， 然后会把数据存在tornado进程的[LRU][183fbcec]缓存里。pv高峰期， redis 和 api的
访问压力也相应增大，从而响应时间增加甚至超时，造成波峰。 总而言之， 拖慢速度罪魁祸首就是redis和api的超时。

#### 优化方案

进行优化工作，首先要寻找优化点，然后针对性解决。

原则上，只要减少redis 和 api 请求就好了。产生redis/api请求的原因是，lru缓存过期。 假设lru5缓存5分钟过期，
然后每台tornado机器产生10次redis/api请求， 我们有200台tornado机器，现在就会产生2000次redis/api请求。但是每台tornado机器是无差别的，
也即是说如果把所有请求都打到一台机器上，缓存过期时，只会产生10次redis/api请求，当然这样是不可以的，单台机器承受不了这样的压力。
可行的方法是根据url分组, 相同的url访问同一台机器，提高缓存利用率。

方案一： nginx 上对url取hash值，打到相应机器上。这样缓存命中率是最高的，但是风险比较大。url的hash结果不可控，高pv的url会打到相同机器上，
负载均衡效果较差。

方案二： 按照url类型进行划分，相同类型的url共享同一组机器。好处是，我们可以事先统计出各类url的负载情况，从而计算出tornado后端机器分组的比例。
比如首页，原先200台机器都会接受首页请求，缓存过期时，总共产生200次redis/api请求，现在我们根据负载情况，只把首页请求打到某10台机器上,
缓存过期时，就只会产生10次redsi/api请求。

#### 方案实施

最终我选择方案二，并且将后端机器分为两组，一组只接收首页／频道页请求，另一组接受其它请求。
下一步就是统计负载占比。我按照如下的公式计算负载占比:

负载占比 ＝ （首页pv * 首页平均响应时间 ＋ 频道页pv * 频道页响应时间）／（总pv * 整体平均响应时间）＊100。

因为来自不同运营商网络(电信、联通、移动)的请求，会打到相应的运营商的后端机房。
保险起见，我计算了每个运营商机房，连续一周，每小时负载占比的变化情况，都在20%左右。
最后也就按照20%的比例, 对每个机房的机器进行分组。

#### 效果

最后首页／新闻页的后端请求，几乎没有了波峰，高峰期也在50ms左右， 效果如此显著，还有一个原因是， 首页／新闻页不依赖api, 分开后， 它们的响应
时间不再受api堵塞的影响。
整体的波峰也从175ms,  下降到了75ms。


  [183fbcec]: https://en.wikipedia.org/wiki/Cache_algorithms#LRU "LRU算法"
